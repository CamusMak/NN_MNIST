{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem 1:__ Design model architecture from scratch using any technique and algorithm\n",
    "covered in the course. Play with layers, and hyperparameters, and report the results of\n",
    "experiments.\n",
    "You will have to submit a written report (.pdf) of 2 pages containing the following and\n",
    "the code:\n",
    "- A paragraph including the architecture details of the best model you\n",
    "managed to conceive, and the training process used to train it, as well as\n",
    "its numerical performance;\n",
    "- A global discussion including:\n",
    "     - Your analysis of the trade-offs between the performance of the final\n",
    "model, the time it takes to train it, and the time needed to tune all the\n",
    "hyper-parameters;<br>\n",
    "     - For each relevant parameter (the various architectural choices, the\n",
    "optimizer configuration, the training process details, etc...), a paragraph\n",
    "explaining what you found about how it impacts the training process and\n",
    "the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "### About data (from [KAGGLE](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database))\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        self.X, self.y = df.values[:, :-1], df.values[:, -1]\n",
    "\n",
    "        self.X = self.X.astype('float32')\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        return [self.X[ind], self.y[ind]]\n",
    "\n",
    "    def split(self, test_size=.2):\n",
    "        test_size = int(test_size * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "\n",
    "        return random_split(self, [train_size, test_size])\n",
    "\n",
    "    def data_loader(self, batch_size=64, shuffle=True, test_size=0.2):\n",
    "        train, test = self.split(test_size=test_size)\n",
    "\n",
    "        train_dl = DataLoader(train, batch_size=batch_size, shuffle=shuffle)\n",
    "        test_dl = DataLoader(test, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        return train_dl, test_dl\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loaders\n",
    "dataset = NNDataset(\"Data/diabetes.csv\")\n",
    "train_loader,test_loader = dataset.data_loader(batch_size=128,shuffle=True,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import ReLU,LeakyReLU,Sigmoid,Linear,CrossEntropyLoss\n",
    "from torch.nn.init import kaiming_uniform_,xavier_uniform_\n",
    "from torch import optim\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNN_1(Module):\n",
    "    \n",
    "    def __init__(self,n_inputs):\n",
    "        \n",
    "        super(CustomNN_1,self).__init__()\n",
    "        \n",
    "        # layer 1\n",
    "        self.linear1 = Linear(n_inputs,32)\n",
    "        kaiming_uniform_(self.linear1.weight,nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        \n",
    "        # layer 2\n",
    "        self.linear2 = Linear(32,16)\n",
    "        kaiming_uniform_(self.linear2.weight,nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        \n",
    "        # output layer \n",
    "        self.linear3 = Linear(16,2)\n",
    "        kaiming_uniform_(self.linear3.weight,nonlinearity='sigmoid')\n",
    "        self.act3 = Sigmoid()\n",
    "\n",
    "    def forward(self,X):\n",
    "        \n",
    "#         X = torch.flatten(X,1)\n",
    "#         X = X.view(X.size(0), -1)\n",
    "\n",
    "        \n",
    "        # layer 1\n",
    "        output = self.linear1(X)\n",
    "        output = self.act1(output)\n",
    "        \n",
    "        # layer 2\n",
    "        output = self.linear2(output)\n",
    "        output = self.act2(output)\n",
    "        \n",
    "        # layer 3\n",
    "        output = self.linear3(output)\n",
    "        output = self.act3(output)\n",
    "        \n",
    "        return output \n",
    "    \n",
    "    def binary(self,output):\n",
    "        return round(output)\n",
    "    \n",
    "    \n",
    "def train_nn(model,device,train_dl,optimizer,loss_function,epoch):\n",
    "    \n",
    "    for batch,(X,y) in enumerate(train_dl):\n",
    "        \n",
    "        X,y = X.to(device),y.to(device)\n",
    "        # get output\n",
    "        output = model(X)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_function(output,y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 4 == 0:\n",
    "\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch * len(X), len(train_dl.dataset),\n",
    "                100. * batch / len(train_dl), loss.item()))\n",
    "            \n",
    "            \n",
    "def test_nn(device,model,test_dl,epoch,loss_function):\n",
    "    \n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch,(X,y) in enumerate(test_dl):\n",
    "            \n",
    "            X,y = X.to(device),y.to(device)\n",
    "            \n",
    "            output = model(X)\n",
    "            prediction = model.binary(output)\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = loss_function(output,y)\n",
    "            \n",
    "            \n",
    "            corret\n",
    "\n",
    "    accuracy = accuracy_score(y,prediction)\n",
    "            \n",
    "    print(f\"\\nEpoch: {epoch}, Test accuracy: {accuracy}\\nTest loss\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomNN_1(\n",
      "  (linear1): Linear(in_features=8, out_features=32, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (linear3): Linear(in_features=16, out_features=2, bias=True)\n",
      "  (act3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_1 = CustomNN_1(8)\n",
    "print(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the model at first has two hidden layer with __ReLU__ activation function for both and output layer with __Sigmoid__ activation function. I am going to train this model using __Stochastic Gradient Gescent__ as optimizer with learning rate = 0.1 and __Cross Entropy__ as a loss function to train this model. As performence metric I am using accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model_1.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/615 (0%)]\tLoss: 0.656563\n",
      "Train Epoch: 0 [412/615 (80%)]\tLoss: 0.721029\n",
      "\n",
      "Epoch: 0, Test accuracy: 0.48\n",
      "\n",
      "\n",
      "Train Epoch: 1 [0/615 (0%)]\tLoss: 0.602324\n",
      "Train Epoch: 1 [412/615 (80%)]\tLoss: 0.575398\n",
      "\n",
      "Epoch: 1, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 2 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 2 [412/615 (80%)]\tLoss: 0.643359\n",
      "\n",
      "Epoch: 2, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 3 [0/615 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 3 [412/615 (80%)]\tLoss: 0.730738\n",
      "\n",
      "Epoch: 3, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 4 [0/615 (0%)]\tLoss: 0.649199\n",
      "Train Epoch: 4 [412/615 (80%)]\tLoss: 0.691903\n",
      "\n",
      "Epoch: 4, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 5 [0/615 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 5 [412/615 (80%)]\tLoss: 0.604524\n",
      "\n",
      "Epoch: 5, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 6 [0/615 (0%)]\tLoss: 0.625762\n",
      "Train Epoch: 6 [412/615 (80%)]\tLoss: 0.662776\n",
      "\n",
      "Epoch: 6, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 7 [0/615 (0%)]\tLoss: 0.696074\n",
      "Train Epoch: 7 [412/615 (80%)]\tLoss: 0.662776\n",
      "\n",
      "Epoch: 7, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 8 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 8 [412/615 (80%)]\tLoss: 0.682194\n",
      "\n",
      "Epoch: 8, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 9 [0/615 (0%)]\tLoss: 0.711699\n",
      "Train Epoch: 9 [412/615 (80%)]\tLoss: 0.740446\n",
      "\n",
      "Epoch: 9, Test accuracy: 0.84\n",
      "\n",
      "\n",
      "Train Epoch: 10 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 10 [412/615 (80%)]\tLoss: 0.721029\n",
      "\n",
      "Epoch: 10, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 11 [0/615 (0%)]\tLoss: 0.610137\n",
      "Train Epoch: 11 [412/615 (80%)]\tLoss: 0.565689\n",
      "\n",
      "Epoch: 11, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 12 [0/615 (0%)]\tLoss: 0.703887\n",
      "Train Epoch: 12 [412/615 (80%)]\tLoss: 0.711320\n",
      "\n",
      "Epoch: 12, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 13 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 13 [412/615 (80%)]\tLoss: 0.614232\n",
      "\n",
      "Epoch: 13, Test accuracy: 0.6\n",
      "\n",
      "\n",
      "Train Epoch: 14 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 14 [412/615 (80%)]\tLoss: 0.672485\n",
      "\n",
      "Epoch: 14, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 15 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 15 [412/615 (80%)]\tLoss: 0.604524\n",
      "\n",
      "Epoch: 15, Test accuracy: 0.6\n",
      "\n",
      "\n",
      "Train Epoch: 16 [0/615 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 16 [412/615 (80%)]\tLoss: 0.662776\n",
      "\n",
      "Epoch: 16, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 17 [0/615 (0%)]\tLoss: 0.602324\n",
      "Train Epoch: 17 [412/615 (80%)]\tLoss: 0.662776\n",
      "\n",
      "Epoch: 17, Test accuracy: 0.48\n",
      "\n",
      "\n",
      "Train Epoch: 18 [0/615 (0%)]\tLoss: 0.664824\n",
      "Train Epoch: 18 [412/615 (80%)]\tLoss: 0.653068\n",
      "\n",
      "Epoch: 18, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 19 [0/615 (0%)]\tLoss: 0.664824\n",
      "Train Epoch: 19 [412/615 (80%)]\tLoss: 0.730738\n",
      "\n",
      "Epoch: 19, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 20 [0/615 (0%)]\tLoss: 0.586699\n",
      "Train Epoch: 20 [412/615 (80%)]\tLoss: 0.721029\n",
      "\n",
      "Epoch: 20, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 21 [0/615 (0%)]\tLoss: 0.641387\n",
      "Train Epoch: 21 [412/615 (80%)]\tLoss: 0.740446\n",
      "\n",
      "Epoch: 21, Test accuracy: 0.56\n",
      "\n",
      "\n",
      "Train Epoch: 22 [0/615 (0%)]\tLoss: 0.719512\n",
      "Train Epoch: 22 [412/615 (80%)]\tLoss: 0.594815\n",
      "\n",
      "Epoch: 22, Test accuracy: 0.56\n",
      "\n",
      "\n",
      "Train Epoch: 23 [0/615 (0%)]\tLoss: 0.696074\n",
      "Train Epoch: 23 [412/615 (80%)]\tLoss: 0.721029\n",
      "\n",
      "Epoch: 23, Test accuracy: 0.56\n",
      "\n",
      "\n",
      "Train Epoch: 24 [0/615 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 24 [412/615 (80%)]\tLoss: 0.662776\n",
      "\n",
      "Epoch: 24, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 25 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 25 [412/615 (80%)]\tLoss: 0.653068\n",
      "\n",
      "Epoch: 25, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 26 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 26 [412/615 (80%)]\tLoss: 0.623941\n",
      "\n",
      "Epoch: 26, Test accuracy: 0.48\n",
      "\n",
      "\n",
      "Train Epoch: 27 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 27 [412/615 (80%)]\tLoss: 0.614233\n",
      "\n",
      "Epoch: 27, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 28 [0/615 (0%)]\tLoss: 0.719512\n",
      "Train Epoch: 28 [412/615 (80%)]\tLoss: 0.682194\n",
      "\n",
      "Epoch: 28, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 29 [0/615 (0%)]\tLoss: 0.680449\n",
      "Train Epoch: 29 [412/615 (80%)]\tLoss: 0.672485\n",
      "\n",
      "Epoch: 29, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 30 [0/615 (0%)]\tLoss: 0.664824\n",
      "Train Epoch: 30 [412/615 (80%)]\tLoss: 0.730738\n",
      "\n",
      "Epoch: 30, Test accuracy: 0.6\n",
      "\n",
      "\n",
      "Train Epoch: 31 [0/615 (0%)]\tLoss: 0.680449\n",
      "Train Epoch: 31 [412/615 (80%)]\tLoss: 0.623941\n",
      "\n",
      "Epoch: 31, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 32 [0/615 (0%)]\tLoss: 0.602324\n",
      "Train Epoch: 32 [412/615 (80%)]\tLoss: 0.740446\n",
      "\n",
      "Epoch: 32, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 33 [0/615 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 33 [412/615 (80%)]\tLoss: 0.672485\n",
      "\n",
      "Epoch: 33, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 34 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 34 [412/615 (80%)]\tLoss: 0.711320\n",
      "\n",
      "Epoch: 34, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 35 [0/615 (0%)]\tLoss: 0.649199\n",
      "Train Epoch: 35 [412/615 (80%)]\tLoss: 0.682194\n",
      "\n",
      "Epoch: 35, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 36 [0/615 (0%)]\tLoss: 0.649199\n",
      "Train Epoch: 36 [412/615 (80%)]\tLoss: 0.643359\n",
      "\n",
      "Epoch: 36, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 37 [0/615 (0%)]\tLoss: 0.664824\n",
      "Train Epoch: 37 [412/615 (80%)]\tLoss: 0.691903\n",
      "\n",
      "Epoch: 37, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 38 [0/615 (0%)]\tLoss: 0.703887\n",
      "Train Epoch: 38 [412/615 (80%)]\tLoss: 0.711320\n",
      "\n",
      "Epoch: 38, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 39 [0/615 (0%)]\tLoss: 0.719512\n",
      "Train Epoch: 39 [412/615 (80%)]\tLoss: 0.691903\n",
      "\n",
      "Epoch: 39, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 40 [0/615 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 40 [412/615 (80%)]\tLoss: 0.721029\n",
      "\n",
      "Epoch: 40, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 41 [0/615 (0%)]\tLoss: 0.711699\n",
      "Train Epoch: 41 [412/615 (80%)]\tLoss: 0.691902\n",
      "\n",
      "Epoch: 41, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 42 [0/615 (0%)]\tLoss: 0.664824\n",
      "Train Epoch: 42 [412/615 (80%)]\tLoss: 0.633650\n",
      "\n",
      "Epoch: 42, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 43 [0/615 (0%)]\tLoss: 0.680449\n",
      "Train Epoch: 43 [412/615 (80%)]\tLoss: 0.653068\n",
      "\n",
      "Epoch: 43, Test accuracy: 0.56\n",
      "\n",
      "\n",
      "Train Epoch: 44 [0/615 (0%)]\tLoss: 0.711699\n",
      "Train Epoch: 44 [412/615 (80%)]\tLoss: 0.711320\n",
      "\n",
      "Epoch: 44, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 45 [0/615 (0%)]\tLoss: 0.610137\n",
      "Train Epoch: 45 [412/615 (80%)]\tLoss: 0.672485\n",
      "\n",
      "Epoch: 45, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 46 [0/615 (0%)]\tLoss: 0.641387\n",
      "Train Epoch: 46 [412/615 (80%)]\tLoss: 0.691902\n",
      "\n",
      "Epoch: 46, Test accuracy: 0.6\n",
      "\n",
      "\n",
      "Train Epoch: 47 [0/615 (0%)]\tLoss: 0.742949\n",
      "Train Epoch: 47 [412/615 (80%)]\tLoss: 0.691902\n",
      "\n",
      "Epoch: 47, Test accuracy: 0.6\n",
      "\n",
      "\n",
      "Train Epoch: 48 [0/615 (0%)]\tLoss: 0.610137\n",
      "Train Epoch: 48 [412/615 (80%)]\tLoss: 0.701611\n",
      "\n",
      "Epoch: 48, Test accuracy: 0.52\n",
      "\n",
      "\n",
      "Train Epoch: 49 [0/615 (0%)]\tLoss: 0.664824\n",
      "Train Epoch: 49 [412/615 (80%)]\tLoss: 0.662776\n",
      "\n",
      "Epoch: 49, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 50 [0/615 (0%)]\tLoss: 0.602324\n",
      "Train Epoch: 50 [412/615 (80%)]\tLoss: 0.701611\n",
      "\n",
      "Epoch: 50, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 51 [0/615 (0%)]\tLoss: 0.719512\n",
      "Train Epoch: 51 [412/615 (80%)]\tLoss: 0.701611\n",
      "\n",
      "Epoch: 51, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 52 [0/615 (0%)]\tLoss: 0.680449\n",
      "Train Epoch: 52 [412/615 (80%)]\tLoss: 0.672485\n",
      "\n",
      "Epoch: 52, Test accuracy: 0.44\n",
      "\n",
      "\n",
      "Train Epoch: 53 [0/615 (0%)]\tLoss: 0.696074\n",
      "Train Epoch: 53 [412/615 (80%)]\tLoss: 0.730737\n",
      "\n",
      "Epoch: 53, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 54 [0/615 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 54 [412/615 (80%)]\tLoss: 0.653068\n",
      "\n",
      "Epoch: 54, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 55 [0/615 (0%)]\tLoss: 0.680449\n",
      "Train Epoch: 55 [412/615 (80%)]\tLoss: 0.691903\n",
      "\n",
      "Epoch: 55, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 56 [0/615 (0%)]\tLoss: 0.664824\n",
      "Train Epoch: 56 [412/615 (80%)]\tLoss: 0.682194\n",
      "\n",
      "Epoch: 56, Test accuracy: 0.56\n",
      "\n",
      "\n",
      "Train Epoch: 57 [0/615 (0%)]\tLoss: 0.649199\n",
      "Train Epoch: 57 [412/615 (80%)]\tLoss: 0.633650\n",
      "\n",
      "Epoch: 57, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 58 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 58 [412/615 (80%)]\tLoss: 0.701611\n",
      "\n",
      "Epoch: 58, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 59 [0/615 (0%)]\tLoss: 0.641387\n",
      "Train Epoch: 59 [412/615 (80%)]\tLoss: 0.555980\n",
      "\n",
      "Epoch: 59, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 60 [0/615 (0%)]\tLoss: 0.696074\n",
      "Train Epoch: 60 [412/615 (80%)]\tLoss: 0.555980\n",
      "\n",
      "Epoch: 60, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 61 [0/615 (0%)]\tLoss: 0.641387\n",
      "Train Epoch: 61 [412/615 (80%)]\tLoss: 0.614233\n",
      "\n",
      "Epoch: 61, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 62 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 62 [412/615 (80%)]\tLoss: 0.682194\n",
      "\n",
      "Epoch: 62, Test accuracy: 0.8\n",
      "\n",
      "\n",
      "Train Epoch: 63 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 63 [412/615 (80%)]\tLoss: 0.643359\n",
      "\n",
      "Epoch: 63, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 64 [0/615 (0%)]\tLoss: 0.594512\n",
      "Train Epoch: 64 [412/615 (80%)]\tLoss: 0.623941\n",
      "\n",
      "Epoch: 64, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 65 [0/615 (0%)]\tLoss: 0.602324\n",
      "Train Epoch: 65 [412/615 (80%)]\tLoss: 0.691902\n",
      "\n",
      "Epoch: 65, Test accuracy: 0.64\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 66 [0/615 (0%)]\tLoss: 0.703887\n",
      "Train Epoch: 66 [412/615 (80%)]\tLoss: 0.730738\n",
      "\n",
      "Epoch: 66, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 67 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 67 [412/615 (80%)]\tLoss: 0.711320\n",
      "\n",
      "Epoch: 67, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 68 [0/615 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 68 [412/615 (80%)]\tLoss: 0.633650\n",
      "\n",
      "Epoch: 68, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 69 [0/615 (0%)]\tLoss: 0.696074\n",
      "Train Epoch: 69 [412/615 (80%)]\tLoss: 0.682194\n",
      "\n",
      "Epoch: 69, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 70 [0/615 (0%)]\tLoss: 0.758574\n",
      "Train Epoch: 70 [412/615 (80%)]\tLoss: 0.643359\n",
      "\n",
      "Epoch: 70, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 71 [0/615 (0%)]\tLoss: 0.696074\n",
      "Train Epoch: 71 [412/615 (80%)]\tLoss: 0.643359\n",
      "\n",
      "Epoch: 71, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 72 [0/615 (0%)]\tLoss: 0.610137\n",
      "Train Epoch: 72 [412/615 (80%)]\tLoss: 0.730737\n",
      "\n",
      "Epoch: 72, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 73 [0/615 (0%)]\tLoss: 0.641387\n",
      "Train Epoch: 73 [412/615 (80%)]\tLoss: 0.633650\n",
      "\n",
      "Epoch: 73, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 74 [0/615 (0%)]\tLoss: 0.641387\n",
      "Train Epoch: 74 [412/615 (80%)]\tLoss: 0.682194\n",
      "\n",
      "Epoch: 74, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 75 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 75 [412/615 (80%)]\tLoss: 0.672485\n",
      "\n",
      "Epoch: 75, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 76 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 76 [412/615 (80%)]\tLoss: 0.653068\n",
      "\n",
      "Epoch: 76, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 77 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 77 [412/615 (80%)]\tLoss: 0.711320\n",
      "\n",
      "Epoch: 77, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 78 [0/615 (0%)]\tLoss: 0.680449\n",
      "Train Epoch: 78 [412/615 (80%)]\tLoss: 0.662776\n",
      "\n",
      "Epoch: 78, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 79 [0/615 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 79 [412/615 (80%)]\tLoss: 0.623941\n",
      "\n",
      "Epoch: 79, Test accuracy: 0.84\n",
      "\n",
      "\n",
      "Train Epoch: 80 [0/615 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 80 [412/615 (80%)]\tLoss: 0.701611\n",
      "\n",
      "Epoch: 80, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 81 [0/615 (0%)]\tLoss: 0.696074\n",
      "Train Epoch: 81 [412/615 (80%)]\tLoss: 0.653068\n",
      "\n",
      "Epoch: 81, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 82 [0/615 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 82 [412/615 (80%)]\tLoss: 0.643359\n",
      "\n",
      "Epoch: 82, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 83 [0/615 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 83 [412/615 (80%)]\tLoss: 0.691903\n",
      "\n",
      "Epoch: 83, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 84 [0/615 (0%)]\tLoss: 0.649199\n",
      "Train Epoch: 84 [412/615 (80%)]\tLoss: 0.604524\n",
      "\n",
      "Epoch: 84, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 85 [0/615 (0%)]\tLoss: 0.649199\n",
      "Train Epoch: 85 [412/615 (80%)]\tLoss: 0.759864\n",
      "\n",
      "Epoch: 85, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 86 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 86 [412/615 (80%)]\tLoss: 0.653068\n",
      "\n",
      "Epoch: 86, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 87 [0/615 (0%)]\tLoss: 0.664824\n",
      "Train Epoch: 87 [412/615 (80%)]\tLoss: 0.614232\n",
      "\n",
      "Epoch: 87, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 88 [0/615 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 88 [412/615 (80%)]\tLoss: 0.623941\n",
      "\n",
      "Epoch: 88, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 89 [0/615 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 89 [412/615 (80%)]\tLoss: 0.604524\n",
      "\n",
      "Epoch: 89, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 90 [0/615 (0%)]\tLoss: 0.641387\n",
      "Train Epoch: 90 [412/615 (80%)]\tLoss: 0.662776\n",
      "\n",
      "Epoch: 90, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 91 [0/615 (0%)]\tLoss: 0.672637\n",
      "Train Epoch: 91 [412/615 (80%)]\tLoss: 0.643359\n",
      "\n",
      "Epoch: 91, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 92 [0/615 (0%)]\tLoss: 0.617949\n",
      "Train Epoch: 92 [412/615 (80%)]\tLoss: 0.662776\n",
      "\n",
      "Epoch: 92, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 93 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 93 [412/615 (80%)]\tLoss: 0.682194\n",
      "\n",
      "Epoch: 93, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 94 [0/615 (0%)]\tLoss: 0.649199\n",
      "Train Epoch: 94 [412/615 (80%)]\tLoss: 0.672485\n",
      "\n",
      "Epoch: 94, Test accuracy: 0.72\n",
      "\n",
      "\n",
      "Train Epoch: 95 [0/615 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 95 [412/615 (80%)]\tLoss: 0.643359\n",
      "\n",
      "Epoch: 95, Test accuracy: 0.68\n",
      "\n",
      "\n",
      "Train Epoch: 96 [0/615 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 96 [412/615 (80%)]\tLoss: 0.740446\n",
      "\n",
      "Epoch: 96, Test accuracy: 0.64\n",
      "\n",
      "\n",
      "Train Epoch: 97 [0/615 (0%)]\tLoss: 0.680449\n",
      "Train Epoch: 97 [412/615 (80%)]\tLoss: 0.653068\n",
      "\n",
      "Epoch: 97, Test accuracy: 0.76\n",
      "\n",
      "\n",
      "Train Epoch: 98 [0/615 (0%)]\tLoss: 0.633574\n",
      "Train Epoch: 98 [412/615 (80%)]\tLoss: 0.701611\n",
      "\n",
      "Epoch: 98, Test accuracy: 0.6\n",
      "\n",
      "\n",
      "Train Epoch: 99 [0/615 (0%)]\tLoss: 0.703887\n",
      "Train Epoch: 99 [412/615 (80%)]\tLoss: 0.594815\n",
      "\n",
      "Epoch: 99, Test accuracy: 0.64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    train_nn(model=model_1,device='cpu',train_dl=train_loader,optimizer=optimizer,loss_function=CrossEntropyLoss(),epoch=epoch)\n",
    "    test_nn(model=model_1,device='cpu',test_dl=test_loader,loss_function=CrossEntropyLoss(),epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
